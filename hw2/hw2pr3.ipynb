{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Start file for hw2pr3 of Big Data Summer 2017\n",
    "\n",
    "The file is seperated into two parts:\n",
    "\t1) the helper functions\n",
    "\t2) the main driver.\n",
    "\n",
    "The helper functions are all functions necessary to finish the problem.\n",
    "The main driver will use the helper functions you finished to report and print\n",
    "out the results you need for the problem.\n",
    "\n",
    "Before attemping the helper functions, please familiarize with pandas and numpy\n",
    "libraries. Tutorials can be found online:\n",
    "http://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\n",
    "\n",
    "First, fill in the the code of step 0 in the main driver to load the data, then\n",
    "please COMMENT OUT any steps in main driver before you finish the corresponding\n",
    "functions for that step. Otherwise, you won't be able to run the program\n",
    "because of errors.\n",
    "\n",
    "After finishing the helper functions for each step, you can uncomment\n",
    "the code in main driver to check the result.\n",
    "\n",
    "Note:\n",
    "1. When filling out the functions below, remember to\n",
    "\t1) Let m be the number of samples\n",
    "\t2) Let n be the number of features\n",
    "\n",
    "2. Please read the instructions and hints carefully, and use the name of the\n",
    "variables we provided, otherwise, the function may not work.\n",
    "\n",
    "3. Remember to comment out the TODO comment after you finish each part.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading data...\n",
      "==> Successfully Loaded data...\n",
      "==> Step 1: RMSE vs lambda...\n",
      "==> Plotting completed.\n",
      "==> The optimal regularization parameter is  8.5977.\n",
      "==> The RMSE on the validation set with the optimal regularization parameter is  0.8340.\n",
      "==> The RMSE on the test set with the optimal regularization parameter is  0.8628.\n",
      "\n",
      "==> Step 2: Norm vs lambda...\n",
      "==> Plotting completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################################\n",
    "#\t    \tMain Driver Function       \t  #\n",
    "###########################################\n",
    "\n",
    "# =============STEP 0: LOADING DATA=================\n",
    "print('==> Loading data...')\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('https://math189sp19.github.io/data/online_news_popularity.csv', \\\n",
    "    sep=', ', engine='python')\n",
    "\n",
    "print('==> Successfully Loaded data...')\n",
    "\n",
    "# split the data frame by type: training, validation, and test\n",
    "train_pct = 2.0 / 3\n",
    "val_pct = 5.0 / 6\n",
    "\n",
    "df['type'] = ''\n",
    "df.loc[:int(train_pct * len(df)), 'type'] = 'train'\n",
    "df.loc[int(train_pct * len(df)) : int(val_pct * len(df)), 'type'] = 'val'\n",
    "df.loc[int(val_pct * len(df)):, 'type'] = 'test'\n",
    "\n",
    "\n",
    "# extracting columns into training, validation, and test data\n",
    "X_train = np.array(df[df.type == 'train'][[col for col in df.columns \\\n",
    "    if col not in ['url', 'shares', 'type']]])\n",
    "y_train = np.array(np.log(df[df.type == 'train'].shares)).reshape((-1, 1))\n",
    "\n",
    "X_val = np.array(df[df.type == 'val'][[col for col in df.columns \\\n",
    "    if col not in ['url', 'shares', 'type']]])\n",
    "y_val = np.array(np.log(df[df.type == 'val'].shares)).reshape((-1, 1))\n",
    "\n",
    "X_test = np.array(df[df.type == 'test'][[col for col in df.columns \\\n",
    "    if col not in ['url', 'shares', 'type']]])\n",
    "y_test = np.array(np.log(df[df.type == 'test'].shares)).reshape((-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# HINT:\n",
    "# \t1) Use np.ones / np.ones_like to create a column of ones\n",
    "#\t2) Use np.hstack to stack the column to the matrix\n",
    "\"*** YOUR CODE HERE ***\"\n",
    "\n",
    "X_train = np.hstack((np.ones((X_train.shape[0],1)),X_train))\n",
    "X_val = np.hstack((np.ones((X_val.shape[0],1)),X_val))\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test))\n",
    "\n",
    "\"*** END YOUR CODE HERE ***\"\n",
    "\n",
    "# Convert data to matrix\n",
    "X_train = np.matrix(X_train)\n",
    "y_train = np.matrix(y_train)\n",
    "X_val = np.matrix(X_val)\n",
    "y_val = np.matrix(y_val)\n",
    "X_test = np.matrix(X_test)\n",
    "y_test = np.matrix(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# PART C\n",
    "# =============STEP 1: RMSE vs lambda=================\n",
    "# NOTE: Fill in code in linreg, findRMSE, and RMSE_vs_lambda for this step\n",
    "\n",
    "print('==> Step 1: RMSE vs lambda...')\n",
    "\n",
    "# find the optimal regularization parameter\n",
    "reg_opt = RMSE_vs_lambda(X_train, y_train, X_val, y_val)\n",
    "print('==> The optimal regularization parameter is {reg: 4.4f}.'.format(\\\n",
    "    reg=reg_opt))\n",
    "\n",
    "# Find the optimal weights and bias for future use in step 3\n",
    "W_with_b_1 = linreg(X_train, y_train, reg=reg_opt)\n",
    "b_opt_1 = W_with_b_1[0]\n",
    "W_opt_1 = W_with_b_1[1: ]\n",
    "\n",
    "# Report the RMSE with the found optimal weights on validation set\n",
    "val_RMSE = find_RMSE(W_with_b_1, X_val, y_val)\n",
    "print('==> The RMSE on the validation set with the optimal regularization parameter is {RMSE: 4.4f}.'.format(\\\n",
    "    RMSE=val_RMSE))\n",
    "\n",
    "# Report the RMSE with the found optimal weights on test set\n",
    "test_RMSE = find_RMSE(W_with_b_1, X_test, y_test)\n",
    "print('==> The RMSE on the test set with the optimal regularization parameter is {RMSE: 4.4f}.'.format(\\\n",
    "    RMSE=test_RMSE))\n",
    "\n",
    "\n",
    "\n",
    "# =============STEP 2: Norm vs lambda=================\n",
    "# NOTE: Fill in code in norm_vs_lambda for this step\n",
    "\n",
    "print('\\n==> Step 2: Norm vs lambda...')\n",
    "norm_vs_lambda(X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.6063682299519"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0.0,100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linreg(X, y, reg=0.0):\n",
    "    \"\"\"\tThis function takes in three arguments:\n",
    "            1) X, the data matrix with dimension m x (n + 1)\n",
    "            2) y, the label of the data with dimension m x 1\n",
    "            3) reg, the parameter for regularization\n",
    "\n",
    "        This function calculates and returns the optimal weight matrix, W_opt.\n",
    "\n",
    "        HINT: Find the numerical solution for part C\n",
    "            1) use np.eye to create identity matrix\n",
    "            2) use np.linalg.solve to solve for W_opt\n",
    "    \"\"\"\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "\n",
    "    n = X.shape[1] - 1\n",
    "\n",
    "    #Use the formula from part c\n",
    "    weird = reg*np.eye(n+1)\n",
    "    weird[0] = 0\n",
    "    W_opt = np.linalg.solve(np.dot(np.transpose(X),X) + weird,np.dot(np.transpose(X),y))\n",
    "\n",
    "\n",
    "    \"*** END YOUR CODE HERE ***\"\n",
    "    return W_opt\n",
    "\n",
    "def predict(W, X):\n",
    "    \"\"\"\tThis function takes in two arguments:\n",
    "            1) W, a weight matrix with bias\n",
    "            2) X, the data with dimension m x (n + 1)\n",
    "\n",
    "        This function calculates and returns the predicted label, y_pred.\n",
    "\n",
    "        NOTE: You don't need to change this function.\n",
    "    \"\"\"\n",
    "    return X * W\n",
    "\n",
    "\n",
    "def find_RMSE(W, X, y):\n",
    "    \"\"\"\tThis function takes in three arguments:\n",
    "            1) W, a weight matrix with bias\n",
    "            2) X, the data with dimension m x (n + 1)\n",
    "            3) y, the label of the data with dimension m x 1\n",
    "\n",
    "        This function calculates and returns the root mean-squared error, RMSE\n",
    "    \"\"\"\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    \n",
    "    #Get prediction and subtract from actual\n",
    "    err = y - predict(W,X)\n",
    "    \n",
    "    #Now square everything\n",
    "    RMSE = np.linalg.norm(err)/np.sqrt(X.shape[0])\n",
    "    \n",
    "    \n",
    "\n",
    "    \"*** END YOUR CODE HERE ***\"\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "\n",
    "def RMSE_vs_lambda(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\tThis function takes in four arguments:\n",
    "            1) X_train, the training data with dimension m x (n + 1)\n",
    "            2) y_train, the label of training data with dimension m x 1\n",
    "            3) X_val, the validation data with dimension m x (n + 1)\n",
    "            4) y_val, the label of validation data with dimension m x 1\n",
    "\n",
    "        This function generates a plot of RMSE vs lambda and returns the\n",
    "        regularization parameter that minimizes RMSE, reg_opt.\n",
    "\n",
    "        HINT: get a list of RMSE following the steps below:\n",
    "            1) Constuct reg_list, a list of regularization parameters with\n",
    "               random uniform sampling\n",
    "            2) Generate W_list, a list of W_opt's according to regularization\n",
    "               parameters generated above\n",
    "            3) Generate, RMSE_list, a list of RMSE according to reg_list\n",
    "    \"\"\"\n",
    "    RMSE_list = []\n",
    "    reg_list = [0]*1000\n",
    "    W_list = []\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    reg_list = np.sort([np.random.uniform(0.0,150.0) for x in reg_list])\n",
    "    for reg in reg_list:\n",
    "        W = linreg(X_train, y_train,reg)\n",
    "        RMSE = find_RMSE(W,X_val,y_val)\n",
    "        W_list = W_list + [W]\n",
    "        RMSE_list = RMSE_list + [RMSE]\n",
    "    \"*** END YOUR CODE HERE ***\"\n",
    "\n",
    "    # Set up plot style\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    # Plot RMSE vs lambda\n",
    "    RMSE_vs_lambda_plot, = plt.plot(reg_list, RMSE_list)\n",
    "    plt.setp(RMSE_vs_lambda_plot, color='red')\n",
    "    plt.title('RMSE vs lambda')\n",
    "    plt.xlabel('lambda')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.savefig('RMSE_vs_lambda.png', format='png')\n",
    "    plt.close()\n",
    "    print('==> Plotting completed.')\n",
    "\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    best = np.argmin(RMSE_list)\n",
    "    reg_opt = reg_list[best]\n",
    "\n",
    "    \"*** END YOUR CODE HERE ***\"\n",
    "    return reg_opt\n",
    "\n",
    "def norm_vs_lambda(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\tThis function takes in four arguments:\n",
    "            1) X_train, the training data with dimension m x (n + 1)\n",
    "            2) y_train, the label of training data with dimension m x 1\n",
    "            3) X_val, the validation data with dimension m x (n + 1)\n",
    "            4) y_val, the label of validation data with dimension m x 1\n",
    "\n",
    "        This function generates a plot of norm of the weights vs lambda.\n",
    "\n",
    "        HINT:\n",
    "            1) You may reuse the code from RMSE_vs_lambda to generate\n",
    "               w_list, the list of weights, and reg_list, the list of\n",
    "               regularization parameters\n",
    "            2) Then generate norm_list, a list of norm by calculating the\n",
    "               norm of each weight\n",
    "    \"\"\"\n",
    "    reg_list = [0]*1000\n",
    "    W_list = []\n",
    "    norm_list = []\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    reg_list = np.sort([np.random.uniform(0.0,150.0) for x in reg_list])\n",
    "    for reg in reg_list:\n",
    "        W = linreg(X_train, y_train,reg)\n",
    "        norm = np.linalg.norm(W)\n",
    "        W_list = W_list + [W]\n",
    "        norm_list = norm_list + [norm]\n",
    "\n",
    "    \"*** END YOUR CODE HERE ***\"\n",
    "\n",
    "    # Set up plot style\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    # Plot norm vs lambda\n",
    "    norm_vs_lambda_plot, = plt.plot(reg_list, norm_list)\n",
    "    plt.setp(norm_vs_lambda_plot, color='blue')\n",
    "    plt.title('norm vs lambda')\n",
    "    plt.xlabel('lambda')\n",
    "    plt.ylabel('norm')\n",
    "    plt.savefig('norm_vs_lambda.png', format='png')\n",
    "    plt.close()\n",
    "    print('==> Plotting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
